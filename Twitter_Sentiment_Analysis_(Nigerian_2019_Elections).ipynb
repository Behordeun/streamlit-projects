{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "Twitter-Sentiment-Analysis (Nigerian_2019_Elections).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Behordeun/streamlit-projects/blob/main/Twitter_Sentiment_Analysis_(Nigerian_2019_Elections).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20a27730"
      },
      "source": [
        "## Importing necessary library"
      ],
      "id": "20a27730"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7MSKK0JJ3kv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a44ad825-f1ad-49ab-ab94-3fa59a32c0a7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "M7MSKK0JJ3kv",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZAlsEJzKbxX",
        "outputId": "40e95f00-58aa-4336-d2b1-2e9412867f2f"
      },
      "source": [
        "!pip install snscrape"
      ],
      "id": "vZAlsEJzKbxX",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting snscrape\n",
            "  Downloading snscrape-0.3.4-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.6.3)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.7/dist-packages (from snscrape) (2.23.0)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from snscrape) (4.2.6)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]->snscrape) (1.7.1)\n",
            "Installing collected packages: snscrape\n",
            "Successfully installed snscrape-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad976000"
      },
      "source": [
        "import snscrape.modules.twitter as sntwitter\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import plotly.graph_objects as go\n",
        "from datetime import datetime"
      ],
      "id": "ad976000",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5f98c26a"
      },
      "source": [
        "## Creating a data frame called \"df\" for storing the data to be scraped.  Here, \"2019 Elections\" was the search keyword\""
      ],
      "id": "5f98c26a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0a35523b"
      },
      "source": [
        "df = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
        "    '\"2019 elections\"').get_items(), 5000000))"
      ],
      "id": "0a35523b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8d75c0b"
      },
      "source": [
        "## Reading the column names from the dataframe to check the attributes"
      ],
      "id": "b8d75c0b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "9f96e36f"
      },
      "source": [
        "df.columns"
      ],
      "id": "9f96e36f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dd8f285"
      },
      "source": [
        "## Calculate the time for scraping the 5000000 tweets\n",
        "\n",
        "Here our search parameters are modified to search for tweets around Abuja within __2017-01-01 to 2021-10-23__ using the keyword __2019 elections__. \n",
        "\n",
        "__NB:__ we set the result to be returned to __5000000__ so we can get as much as possible results (tweets)."
      ],
      "id": "4dd8f285"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f91acb1a"
      },
      "source": [
        "# Set start time\n",
        "start_time = datetime.now()\n",
        "#Creating dataframe called 'data' and storing the tweets\n",
        "data = pd.DataFrame(itertools.islice(sntwitter.TwitterSearchScraper(\n",
        "    '\"2019 elections near:Abuja since:2017-01-01 until:2021-10-23\"').get_items(), 5000000))\n",
        "# Set end time\n",
        "end_time = datetime.now()\n",
        "#Printing the time duration for scraping these tweets\n",
        "print('Duration: {}'.format(end_time - start_time))"
      ],
      "id": "f91acb1a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "986510d1"
      },
      "source": [
        "#keeping only date, id, content, user, and url and stored into dataframe called 'df'\n",
        "df = data[['date', 'id', 'content', 'username', 'url']]"
      ],
      "id": "986510d1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6d632678"
      },
      "source": [
        "# If you don't have transformers library installed before, kindly install it using the command:\n",
        "# !pip install transformers.\n",
        "\n",
        "# PS: Remember to remove the leading # in front of \"pip install transformers\""
      ],
      "id": "6d632678",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5afbc451"
      },
      "source": [
        "#Importing the pipeline from Transformers.\n",
        "from transformers import pipeline\n",
        "sentiment_classifier = pipeline('sentiment-analysis')"
      ],
      "id": "5afbc451",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "216102d8"
      },
      "source": [
        "#Taking only 1000000 (20%) records and creating new dataframe called df1\n",
        "df1 = df.head(1000000)\n",
        "# Passing the tweets into the sentiment pipeline and extracting the sentiment score and label\n",
        "df1 = (df1.assign(sentiment = lambda x: x['content'].apply(lambda s: sentiment_classifier(s)))\n",
        ".assign(\n",
        "label = lambda x: x['sentiment'].apply(lambda s: (s[0]['label'])),\n",
        "score = lambda x: x['sentiment'].apply(lambda s: (s[0]['score']))))\n",
        "df1.head()"
      ],
      "id": "216102d8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fadb5344"
      },
      "source": [
        "#checking the 1000th tweet, to check the sentiment label whether it is \"positive\" or “negative”\n",
        "df1['content'][1000]"
      ],
      "id": "fadb5344",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cf75c3d9"
      },
      "source": [
        "# Visualizing the sentiments\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Bar(x = df1[\"score\"],\n",
        "y = df1[\"label\"],\n",
        "orientation = \"h\")) #set orientation to horizontal because we want to flip the x and y-axis\n",
        "fig.update_layout(plot_bgcolor = \"white\")\n",
        "fig.show()"
      ],
      "id": "cf75c3d9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02bc9ec9"
      },
      "source": [
        "# Taking the entire 5000000 (100%) records and creating new dataframe called df1\n",
        "df2 = df\n",
        "# Passing the tweets into the sentiment pipeline and extracting the sentiment score and label\n",
        "df2 = (df2.assign(sentiment = lambda x: x['content'].apply(lambda s: sentiment_classifier(s)))\n",
        ".assign(\n",
        "label = lambda x: x['sentiment'].apply(lambda s: (s[0]['label'])),\n",
        "score = lambda x: x['sentiment'].apply(lambda s: (s[0]['score']))))\n",
        "df2.head()"
      ],
      "id": "02bc9ec9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "884d254d"
      },
      "source": [
        "#Visualizing the sentiments\n",
        "fig1 = go.Figure()\n",
        "fig1.add_trace(go.Bar(x = df2[\"Sentiment score\"],\n",
        "y = df2[\"Sentiment label\"],\n",
        "orientation = \"h\")) #set orientation to horizontal because we want to flip the x and y-axis\n",
        "fig1.update_layout(plot_bgcolor = \"white\")\n",
        "fig1.show()"
      ],
      "id": "884d254d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "492f0bad"
      },
      "source": [
        "df2.to_csv('/content/drive/MyDrive/Datasets/Abj-Elect-Tweets-Sentiment.csv', index=True)"
      ],
      "id": "492f0bad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f785dc0c"
      },
      "source": [
        "df1.to_csv('/content/drive/MyDrive/Datasets/Abj-Elect-Tweets-Sentiment1.csv', index=True)"
      ],
      "id": "f785dc0c",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "964d1976"
      },
      "source": [
        ""
      ],
      "id": "964d1976",
      "execution_count": null,
      "outputs": []
    }
  ]
}